{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98582d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd30e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_DATA = False\n",
    "\n",
    "class DogsVSCats:\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"./data/PetImages/Cat\"\n",
    "    DOGS = \"./data/PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    dog_count = 0\n",
    "    cat_count = 0\n",
    "    \n",
    "    \n",
    "    def build_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                try:\n",
    "                    path = os.path.join(label, f)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                    if img is None:\n",
    "                        print(f\"Warning: {path} could not be read. Skipping this image.\")\n",
    "                        continue\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))  # pyright: ignore[reportCallIssue]\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "                    if label == self.CATS:\n",
    "                        self.cat_count +=1\n",
    "                    if label == self.DOGS:\n",
    "                        self.dog_count +=1\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\",np.array(self.training_data, dtype=object), True, fix_imports=True)\n",
    "        # print(\"CATS: \", self.cat_count)\n",
    "        # print(\"DOGS: \", self.dog_count+ self.cat_count)\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    dogs_vs_cats = DogsVSCats()\n",
    "    dogs_vs_cats.build_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae8e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35116669",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch._tensor import Tensor\n",
    "\n",
    "\n",
    "from torch._tensor import Tensor\n",
    "from torch.nn.modules.conv import Conv2d\n",
    "\n",
    "\n",
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class ConvolutionalNeuralNetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convolutional_layer_one: Conv2d = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5)\n",
    "        self.convolutional_layer_two: Conv2d = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5)\n",
    "        self.convolutional_layer_three: Conv2d = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5)\n",
    "        \n",
    "        # Initializing a final layer for distribution\n",
    "        \"\"\"\n",
    "        The first argument -1 means 'for any size of tensor'.\n",
    "        The second (hint 1) represent the entire batch of data.\n",
    "        The 50 by 50 represents the size of images within the batch of data.\n",
    "        \"\"\"\n",
    "        x: Tensor = T.randn(50, 50).view(-1, 1, 50, 50)\n",
    "        self._to_linear = 0\n",
    "        self.layer_pooling(x)\n",
    "        self.fully_connected_layer_one = nn.Linear(self._to_linear, 512)\n",
    "        # Final layer\n",
    "        self.fully_connected_layer_two = nn.Linear( 512, 2)\n",
    "        \n",
    "    def layer_pooling(self, layer: Tensor) -> Tensor:\n",
    "        output_layer_one: Tensor=  F.max_pool2d(F.relu(self.convolutional_layer_one(layer)), (2,2))\n",
    "        output_layer_two: Tensor=  F.max_pool2d(F.relu(self.convolutional_layer_two(output_layer_one)), (2,2))\n",
    "        layer_pool: Tensor=  F.max_pool2d(F.relu(self.convolutional_layer_three(output_layer_two)), (2,2))\n",
    "\n",
    "        if self._to_linear == 0:\n",
    "            layer_one_shape = layer_pool[0].shape[0]\n",
    "            layer_two_shape = layer_pool[0].shape[1]\n",
    "            layer_three_shape = layer_pool[0].shape[2]\n",
    "            product_of_layer_dimensions = (layer_one_shape * layer_two_shape * layer_three_shape)\n",
    "            self._to_linear =  product_of_layer_dimensions\n",
    "        return layer_pool\n",
    "    \n",
    "    def flattenFlattening(self, layer: Tensor) -> Tensor | None:\n",
    "        layer_hat: Tensor = self.layer_pooling(layer)\n",
    "        if self._to_linear != 0:\n",
    "            layer_hat = layer_hat.view(-1, self._to_linear)\n",
    "            return  layer_hat\n",
    "        return None\n",
    "\n",
    "    def forward(self, layer) -> Tensor | None:\n",
    "        flatten_final_layer: Tensor | None = self.flattenFlattening(layer)\n",
    "        if flatten_final_layer is not None:\n",
    "            flatten_final_layer = F.relu(input=self.fully_connected_layer_one(flatten_final_layer))\n",
    "            final_layer = self.fully_connected_layer_two(flatten_final_layer)\n",
    "            return F.softmax(final_layer, dim=1)\n",
    "neural_net: ConvolutionalNeuralNetWork = ConvolutionalNeuralNetWork()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6bbc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(neural_net.parameters(), lr=0.001)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "images = Tensor(np.array([image[0] for image in training_data]))\n",
    "images = images/255.0\n",
    "y = Tensor([y[1] for y in training_data])\n",
    "\n",
    "# The percentage of data we take from the set for sampling\n",
    "sample_percent = 0.1\n",
    "sample_end_index = int(len(images) * sample_percent)\n",
    "Image_sample = images[:-sample_end_index]\n",
    "y_sample = y[:-sample_end_index]\n",
    "\n",
    "Image_test_sample = images[-sample_end_index:]\n",
    "y_test = y[-sample_end_index:]\n",
    "\n",
    "print(len(Image_sample))\n",
    "print(len(Image_test_sample))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 2\n",
    "loss = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for index in tqdm(range(0, len(Image_sample), BATCH_SIZE)):\n",
    "        batch_images = Image_sample[index: index+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = y_sample[index: index+BATCH_SIZE]\n",
    "        neural_net.zero_grad()\n",
    "        outputs = neural_net(batch_images)\n",
    "        loss = loss_func(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d578680",
   "metadata": {},
   "source": [
    "# Run our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with T.no_grad():\n",
    "    for index in tqdm(range(len(Image_test_sample))):\n",
    "        real_class = T.argmax(y_test[index])\n",
    "        net_out = neural_net(Image_test_sample[index].view(-1, 1, 50, 50))[0]\n",
    "        \n",
    "        predicted_class = T.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct +=1\n",
    "        total +=1\n",
    "print(f\"Accuracy: {(round(correct/total,3)*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c855ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T.cuda.is_available()\n",
    "\n",
    "device = T.device(\"cuda\" if T.cuda.is_available() else \"cpu\")\n",
    "T.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
